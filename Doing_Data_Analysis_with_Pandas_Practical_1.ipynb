{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis with Python Pandas\n",
    "In this notebook you will be going through the basics of interrogating and analysing data in Python with the Pandas package.  __[Pandas](https://pandas.pydata.org/pandas-docs/stable/10min.html)__, using data structures known as Dataframes which arrange data in a form similar to an excel spreadsheet, is a very powerful tool for quickly and effectively working with tabular data.  In this practical we will be investigating the [Climate Change: Earth Surface Temperature](https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data/data) dataset available on the Kaggle website.  We will learn to: load a .csv file into a dataframe; explore the data held in the dataframe; convert time information from string form into more useful time objects; subset a dataframe; reduce a dataframe through the groupby method; fit a simple model using the numpy package; and finally do some visualisation.  This might seem like a lot of things to do, but Pandas makes most of it quite straightforward!    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in Python Packages\n",
    "Prior to doing any work on the data, we need to make sure that the packages that we will be using are accesible in this notebook.  This is done with the __<font color=green>import</font>__ statement, which in effect makes the package available for use within Python. We need to import pandas, numpy and pyplot from matplotlib for this practical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the dataset\n",
    "The data we are going to be using is in .csv format.  These files are in a comma separated value form (hence .csv) and are very easily read in by Pandas using the __[read_csv](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html)__ method.  Pandas has a lot of different methods!  Finding the right one for the task might seem problematic, however the [documentation](http://pandas.pydata.org/pandas-docs/stable/) is your friend here (along with Google) and is very well put together.  Let's move on and get the data read in.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = 'data/surface_temps/GlobalLandTemperaturesByCountry.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First a little preprocessing to get rid of non-countries, and also to retain only European parts of colonial countries.\n",
    "\n",
    "df = df[~df['Country'].isin(\n",
    "    ['Denmark', 'France', 'Europe', 'Netherlands',\n",
    "     'United Kingdom', 'Africa', 'South America'])]\n",
    "\n",
    "df = df.replace(\n",
    "   ['Denmark (Europe)', 'France (Europe)', 'Netherlands (Europe)', 'United Kingdom (Europe)'],\n",
    "   ['Denmark', 'France', 'Netherlands', 'United Kingdom'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First look at the data\n",
    "So we have now loaded the data into the __df__ variable.  However, it would be good to have an idea of: what sort of variable it is?  What does it contain?  How many observations are there? And so on...  Let's answer some of these questions now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so it is a Pandas __[DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)__.  This is the key data structure in Pandas.  How about getting a look at some of the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The __[head](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.head.html)__ method lets us see the first 5 entries of the dataframe.  Notice that a DataFrame has a similar structure to an Excel table, and that is a good way to think about it.  It is a set of numbered rows and named columns, which each row being a data sample and each column being a feature of the data.  Also, the __[tail](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.tail.html)__ method lets us look at the end of the dataframe..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, what are the data features contained in the dataframe?  Most are self explanatory.  But lets go through them anyway, just so we are sure.  The first set of rows are the data indexes, from this we can see that there are 577461 data samples.  The __dt__ column gives us the date at a monthly resolution, __AverageTemperature__ the mean temperature for that month, __AverageTemperatureUncertainty__ the 95% confidence interval around the average (so we are 95% certain the true mean temperature is this close to the reported mean), and the __Country__.  How about the NaNs?  These represent Not a Number, and mean here that there is missing data.  We can also get information on the type of data held within the DataFrame amongst other things, using the __[info](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.info.html)__ method:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see the number of entries in each column, along with the datatype."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get basic statistics on the numerical data using __[describe](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html)__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Let's now take a closer look at the information contained in a column, in this case __dt__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closer look at a DataFrame column\n",
    "Firstly, before we go into the __dt__ column in more details, let's have a look at what data type a column is in Pandas?  Is it still a DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so it is a Pandas __[Series](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html)__.  It is always good to know what data type you are working with, as then you can more easily know what methods you might be able to apply to it.  Also, note that we use dot notation to access the series.  There are other ways, but I find this easiest to remember.  How about the datatype of the data samples contained in the series? To do this, let's first select one of the items in the series using the __[iloc](https://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-integer)__ method, and then check its type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the time-samples are of type string, which essentially means that they are text.  We can turn them into something that may be more useful for data analysis, in the form of a timestamp.  Timestamps allow us to work with time data much more easily.  So let's have a go convert from string to a timestamp with Pandas using the __[to_datetime](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.to_datetime.html)__ method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So using this method we have converted our string to a time object and this gives us a potentially more useful datatype for doing timeseries analysis.  Let apply this to the entire __dt__ series to convert them all from strings to timestamps:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what have done above is reassign the rows in __dt__ column so that each sample now contains the the timestamp generated from the string that was previously in the row.  It should be mentioned that converting from strings to datetimes is not always as easy as this, as the string formats for time can be quite variable, but there is plenty of information in the to_datetime documentation showing you how to deal with different formats.  Now check the dataframe info again to see what has changed.  Note that __dt__ is now of type datetime, which is what we want.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsetting a Dataframe\n",
    "Rather than working with all the data in a DataFrame it is sometimes useful to subset it down to a more specific set of samples.  In this instance we are going to subset to all observations since January 1970 as it is in this period that global temperatures have been rising the fastest.  There are various methods to subset the dataframe.  We are going to reset in the index to the Datetime column and then do the subsetting based on the index, but you can do this similarly using any column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doing some data analysis\n",
    "Now lets find the five countries with the largest and the five with the smallest relatvie temperature changed since 1970.  One way to do this (though maybe not the best way!) is to fit a line to the annual mean temperature time series, and then the slope, __m__, provides indication of the rate of change in temperature through time.  Let's first investigate this with one example country:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the annual mean temperatures we will need to use a Pandas function called __[groupby](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html)__.  This lets you aggregate data which has a shared variable value, in this case the year of the index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "what_to_group = df_1970_present_UK.index.year\n",
    "variables_of_interest = {'AverageTemperature': np.mean}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our yearly observations let's plot the timeseries for the UK to have a look at it using __[plot](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.plot.html)__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's fit a line to these data points using the numpy package, specifically the __[polyfit](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.polyfit.html)__ method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = grouped_df_1970_present_UK.index\n",
    "y = grouped_df_1970_present_UK.AverageTemperature\n",
    "order = 1  # by setting the order to 1 we get a linear fit.\n",
    "m, c = np.polyfit(x, y, order)  # the slope, m, gives us the rate of change in temperature per year.\n",
    "print m, c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now using the linear model we have generated let's make a 'fit' column with it in the dataframe that will allow us to visualise it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so since 1970 you could argue from this data that there has been a ~1 degree celcius rise in land surface temperature in the United Kingdom.  Now let's find the those countries where the temperature is changing most and least quickly, as determined by the slope, __m__. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Exercises (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Countries with Most and Least quickly changing temperatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine the rate of temperature change in any given country we again need to group the monthly data into years, but this time we also need to group by country.  This will give us the annual temperature for every country since 1970:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "what_to_group = [df_1970_present.index.year, df_1970_present.Country]\n",
    "variables_of_interest = {'AverageTemperature': np.mean}\n",
    "\n",
    "grouped_df_1970_present_global = df_1970_present.groupby(what_to_group).agg(variables_of_interest)\n",
    "grouped_df_1970_present_global.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a double index in the dataframe (indexed on dt and Country) it is helpful to reset the index to something more managable, and move the index values back into the dataframe itself.  Let's do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df_1970_present_global.reset_index(inplace=True)  # here resetting index makes it easier to work with\n",
    "grouped_df_1970_present_global.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to evalute the annual temperature time series for each country.  This is going to require a Python __for loop__, where we step over each country, subset the dataframe to only those rows with information relevant to the current country and then get the slope using the numpy polyfit method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "countries = []  # create a list to hold the country information\n",
    "rate_of_temperature_change = [] # create a list to hold the slope information\n",
    "for country in set(grouped_df_1970_present_global.Country):  # loop over the set of countries \n",
    "    \n",
    "    # lets get the grouped data for the current country under analysis\n",
    "    country_df = grouped_df_1970_present_global[grouped_df_1970_present_global.Country == country]\n",
    "    try:\n",
    "        \n",
    "        # do the polyfit\n",
    "        x = country_df.dt\n",
    "        y = country_df.AverageTemperature\n",
    "        order = 1\n",
    "        m, c = np.polyfit(x, y, order)\n",
    "        \n",
    "        countries.append(country)\n",
    "        rate_of_temperature_change.append(m)\n",
    "    except:\n",
    "        continue  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have two lists, containing the information on the the slope, i.e. the rate of temperature change per annum, and also the country.  Let's generate a Pandas dataframe from these two lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_of_temp_change_df = pd.DataFrame({'Country': countries,\n",
    "                                       'Temp_Slope': rate_of_temperature_change})\n",
    "rate_of_temp_change_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the last step, let's sort the values in the new dataframe, and then print out the five countries with the largest rates of temperature change since 1970 using the __head__ method, and then the five countries with the smallest rates of temperature change since 1970 using the __tail__ method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rate_of_temp_change_df.sort_values('Temp_Slope', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_of_temp_change_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_of_temp_change_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we now know which countries have experienced the largest and smallest rates of annual temperature change since 1970.  Finally, as an additional step let's visualise it for all countries with Plotly:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation with Plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly as pl\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "\n",
    "data = [ dict(\n",
    "        type = 'choropleth',\n",
    "        locations = rate_of_temp_change_df.Country,\n",
    "        z = rate_of_temp_change_df.Temp_Slope,\n",
    "        locationmode = 'country names',\n",
    "        text = rate_of_temp_change_df.Country,\n",
    "        marker = dict(\n",
    "            line = dict(color = 'rgb(0,0,0)', width = 1)),\n",
    "            colorbar = dict(autotick = True, tickprefix = '', \n",
    "            title = '\\nÂ°C/yr')\n",
    "            )\n",
    "       ]\n",
    "\n",
    "layout = dict(\n",
    "    title = 'Rate of Temperature Change since 1970 by Country',\n",
    "    geo = dict(\n",
    "        showframe = False,\n",
    "        showocean = True,\n",
    "        oceancolor = 'rgb(0,255,255)',\n",
    "        projection = dict(\n",
    "        type = 'orthographic',\n",
    "            rotation = dict(\n",
    "                    lon = 0,\n",
    "                    lat = 10),\n",
    "        ),\n",
    "        lonaxis =  dict(\n",
    "                showgrid = True,\n",
    "                gridcolor = 'rgb(102, 102, 102)'\n",
    "            ),\n",
    "        lataxis = dict(\n",
    "                showgrid = True,\n",
    "                gridcolor = 'rgb(102, 102, 102)'\n",
    "                )\n",
    "            ),\n",
    "        )\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "py.iplot(fig, validate=False, filename='worldmap')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
