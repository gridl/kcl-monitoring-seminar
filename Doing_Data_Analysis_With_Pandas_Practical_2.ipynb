{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data and Objectives\n",
    "In this practical you will be investigating the impact of winter heating on the levels of Particulate Matter in Beijing.  Using [this](https://www.kaggle.com/crawford/pm25-data-for-five-chinese-cities) kaggle dataset, taken from [this](http://www.stat-center.pku.edu.cn/Stat/Uploads/Files/[20151120_1009]Liang-etal-Chen-PRSA-PM2.5.pdf) paper you will be first working to understand what is in your data, and then looking to build see if there is any relation between temperature and particulate matter.  Use the methods from the last pratical to guide you in what Pandas methods to use!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Python Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Dataset\n",
    "Load the .csv file (contained in the fname variable) into a pandas dataframe usng the appropriate pandas method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = 'data/pm25-data-of-five-chinese-cities/BeijingPM20100101_20151231.csv'\n",
    "df = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial look at the Data\n",
    "First have a look at the first and last five rows in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now get some basic statistics about the data using the appropriate Pandas method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now get some information on the size and shape of the dataframe and the data types of the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset and group the Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First run the piece of code below which takes the date and time columns and puts them together as one datetime object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_column_list = ['year', 'month', 'day', 'hour']\n",
    "df['dt'] = pd.to_datetime(df[time_column_list])\n",
    "df.drop(time_column_list, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now set the datetime (__dt__ column) as the index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now subset the dataframe so we have only data from 2014, the mask you can use to do this has been done already:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df.index >= \"2014\") & (df.index < \"2015\")\n",
    "df_2014 = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now group the PM data so that we get daily averages.  The __what_to_group__ over and __variables_of_interest__ have been defined, you need to define the grouping method and write the groupby code (i.e. how to aggregate the daily data): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "what_to_group = df_2014.index.dayofyear\n",
    "variables_of_interest = {'PM_Dongsi': ,   # <- define aggregation method in here\n",
    "                         'PM_Dongsihuan': , # <- define aggregation method in here\n",
    "                         'PM_Nongzhanguan': , # <- define aggregation method in here\n",
    "                         'PM_US Post': } # <- define aggregation method in here\n",
    "\n",
    "grouped_2014_df = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now make sure you have the right number of data samples in the grouped dataframe (there should be 365 entries!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some initial data visualisation\n",
    "Now for the last step, lets plot all the data to see how the PM2.5 changes at each of the stations through the year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
